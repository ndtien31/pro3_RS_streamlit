import streamlit as st
import pandas as pd
import numpy as np
import json
from io import StringIO
from scipy.spatial.distance import euclidean

# Load centroids vÃ  scaler
with open("pyspark/centroids.json", "r") as f:
    centroids = np.array(json.load(f))

with open("pyspark/scaler_minmax.json", "r") as f:
    scaler = json.load(f)
    min_vals = np.array(scaler["min"])
    max_vals = np.array(scaler["max"])

# HÃ m scale dá»¯ liá»‡u
def minmax_scale(row, min_vals, max_vals):
    return (row - min_vals) / (max_vals - min_vals + 1e-8)

# Dá»± Ä‘oÃ¡n cá»¥m
def predict_cluster(point, centroids):
    distances = [euclidean(point, center) for center in centroids]
    return int(np.argmin(distances))

# Gá»£i Ã½ cho tá»«ng cá»¥m
cluster_suggestions = {
    1: "ğŸŸ¢ NhÃ³m tiá»m nÄƒng cao - nÃªn táº­p trung upsell hoáº·c giá»¯ chÃ¢n.",
    2: "ğŸŸ¡ NhÃ³m bÃ¬nh thÆ°á»ng - cÃ³ thá»ƒ nuÃ´i dÆ°á»¡ng thÃªm.",
    3: "ğŸ”´ NhÃ³m cÃ³ giÃ¡ trá»‹ tháº¥p - cÃ¢n nháº¯c chiáº¿n dá»‹ch khuyáº¿n mÃ£i.",
    0: "ğŸ”µ NhÃ³m má»›i hoáº·c chÆ°a rÃµ hÃ nh vi - nÃªn theo dÃµi thÃªm.",
}

# Giao diá»‡n chÃ­nh
st.title("ğŸ“Š Dá»± Ä‘oÃ¡n phÃ¢n cá»¥m khÃ¡ch hÃ ng RFM (KMeans)")

st.markdown("### ğŸ“¥ BÆ°á»›c 1: Táº£i file CSV máº«u")
csv_template = "Recency,Frequency,Monetary\n10,5,100\n30,2,40\n7,8,300\n15,4,120\n90,1,20"
st.download_button(
    label="â¬‡ï¸ Táº£i file máº«u (.csv)",
    data=csv_template,
    file_name="rfm_template.csv",
    mime="text/csv"
)

st.markdown("### ğŸ“¤ BÆ°á»›c 2: Táº£i lÃªn file báº¡n Ä‘Ã£ Ä‘iá»n")
uploaded_file = st.file_uploader("ğŸ“ Chá»n file CSV", type="csv")

if uploaded_file is not None:
    try:
        df = pd.read_csv(uploaded_file)
        st.write("ğŸ“‹ Dá»¯ liá»‡u báº¡n Ä‘Ã£ táº£i lÃªn:")
        st.dataframe(df)

        if st.button("ğŸ” Dá»± Ä‘oÃ¡n cá»¥m"):
            # Scale dá»¯ liá»‡u
            scaled_data = df.apply(lambda row: minmax_scale(np.array(row), min_vals, max_vals), axis=1)
            scaled_data = np.vstack(scaled_data)

            # Dá»± Ä‘oÃ¡n cá»¥m
            clusters = [predict_cluster(x, centroids) for x in scaled_data]
            df["Cluster"] = clusters
            df["Gá»£i Ã½ hÃ nh Ä‘á»™ng"] = df["Cluster"].apply(lambda x: cluster_suggestions.get(x, "KhÃ´ng xÃ¡c Ä‘á»‹nh"))

            st.success("âœ… ÄÃ£ phÃ¢n cá»¥m xong!")
            st.markdown("### ğŸ“ˆ Káº¿t quáº£ phÃ¢n cá»¥m vÃ  gá»£i Ã½:")
            st.dataframe(df)

            # Cho táº£i káº¿t quáº£ vá»
            csv_result = df.to_csv(index=False).encode("utf-8")
            st.download_button("ğŸ“¤ Táº£i káº¿t quáº£ vá»", csv_result, file_name="rfm_cluster_result.csv", mime="text/csv")

    except Exception as e:
        st.error(f"Lá»—i khi xá»­ lÃ½ file: {e}")
